# 🧪 크롤링 에이전트 테스트 시나리오 (Crawler Testing Scenarios)

## 🎯 **테스트 전략 개요**

### **3단계 테스트 접근법**
1. **🔬 단위 테스트**: 개별 사이트별 기본 크롤링 검증
2. **🔗 통합 테스트**: 멀티소스 동시 수집 및 데이터 처리 파이프라인 검증  
3. **⚡ 성능 테스트**: 대용량 데이터 처리 및 시스템 부하 테스트

## 🔬 **Stage 1: 단위 테스트 (Unit Testing)**

### **의료진 전용 사이트 테스트**
```bash
# 🏥 대한의사협회 (KMA) 기본 테스트
claude --debug --print "Playwright로 대한의사협회 공지사항 페이지에 접속해서 제목, 날짜, 내용 추출이 정상 작동하는지 테스트"

# ✅ 성공 기준: 최신 공지사항 5개 이상 추출, 모든 필수 필드 존재
claude --print "추출된 데이터가 JSON 스키마를 준수하고, 한글 인코딩이 정상인지 검증"

# 📋 식약처 안전성 정보 테스트
claude --debug --print "Context7에서 식약처 사이트 구조를 확인하고, Playwright로 의약품 안전성 서한 페이지 크롤링 테스트"

# ✅ 성공 기준: PDF 링크 추출, 약물명 정확 파싱, 안전성 정보 분류
claude --print "Sequential로 추출된 안전성 정보를 긴급도에 따라 분류하는 로직 테스트"
```

### **의료 뉴스 사이트 테스트**
```bash
# 📰 메디컬타임즈 크롤링 테스트  
claude --debug --print "Playwright로 메디컬타임즈 메인 페이지에서 최신 뉴스 헤드라인과 요약 추출 테스트"

# ✅ 성공 기준: 기사 제목, 작성자, 발행일, 본문 일부 정확 추출
claude --print "추출된 뉴스 데이터에서 의료 전문용어가 올바르게 인식되고 태깅되는지 확인"

# 🔄 청년의사 동적 콘텐츠 테스트
claude --debug --print "Sequential로 청년의사 사이트의 AJAX 로딩 패턴을 분석하고, 동적 콘텐츠 크롤링 테스트"

# ✅ 성공 기준: JavaScript 렌더링 후 추가 로드되는 기사까지 완전 수집
claude --print "무한 스크롤이나 페이지네이션이 있는 경우 모든 콘텐츠 수집 확인"
```

### **학술 데이터베이스 테스트**
```bash
# 📚 PubMed API + 웹크롤링 하이브리드 테스트
claude --debug --print "Context7에서 PubMed API 사용법을 확인하고, '당뇨병 치료' 키워드로 최신 논문 10편 검색 테스트"

# ✅ 성공 기준: PMID, 제목, 저자, 초록, 저널명, DOI 완전 추출
claude --print "Playwright로 PubMed 웹사이트에서 추가 메타데이터(인용수, 영향지수)도 수집하는지 테스트"

# 🔗 Google Scholar 인용 관계 테스트
claude --debug --print "Sequential을 사용해서 특정 논문의 인용 논문과 피인용 논문 네트워크를 추출하는 테스트"
```

## 🔗 **Stage 2: 통합 테스트 (Integration Testing)**

### **멀티소스 동시 수집 테스트**
```bash
# 🌐 5개 사이트 병렬 크롤링 테스트
claude --debug --print "Playwright로 대한의사협회, 식약처, 메디컬타임즈, 청년의사, 데일리메디를 동시에 크롤링하는 스트레스 테스트"

# ✅ 성공 기준: 모든 사이트에서 데이터 수집, 5분 이내 완료, 메모리 사용량 <1GB
claude --print "Sequential로 각 사이트별 수집 상태를 실시간 모니터링하고 실패 시 자동 복구 테스트"

# 🔄 데이터 처리 파이프라인 통합 테스트
claude --debug --print "수집된 원시 데이터가 전처리-구조화-저장-시각화 파이프라인을 완전히 통과하는지 end-to-end 테스트"

# ✅ 성공 기준: 원시 데이터 → Notion 대시보드까지 15분 이내 완전 처리
claude --print "Context7에서 데이터 품질 기준을 확인하고, 최종 결과물의 품질 점수가 80점 이상인지 검증"
```

### **실시간 변화 감지 테스트**
```bash
# ⚡ 웹페이지 변화 감지 정확성 테스트
claude --debug --print "테스트용으로 특정 페이지를 수동으로 수정한 후, 변화 감지 시스템이 10분 이내에 감지하는지 테스트"

# ✅ 성공 기준: 변화 감지 후 자동 재수집, 변경 내용 diff 정확 생성
claude --print "Sequential로 변화의 중요도를 자동 평가하고, 긴급도에 따른 알림 발송 테스트"

# 🔔 키워드 알림 시스템 테스트
claude --debug --print "'의료사고', '약물 리콜' 등 긴급 키워드가 포함된 가상 뉴스로 즉시 알림 시스템 테스트"
```

### **데이터 품질 검증 테스트**
```bash
# 🔍 중복 데이터 처리 테스트
claude --debug --print "동일한 뉴스가 여러 사이트에 게재된 경우, 중복 제거 알고리즘이 정확히 작동하는지 테스트"

# ✅ 성공 기준: 90% 이상의 중복 탐지율, 중요 정보 손실 없음
claude --print "Sequential로 여러 소스의 동일 정보를 교차 검증하고 신뢰도 점수를 정확히 산출하는지 테스트"

# 🧹 데이터 정제 효과성 테스트
claude --debug --print "HTML 태그, 광고, 불필요한 콘텐츠가 포함된 원시 데이터를 완전히 정제하는지 테스트"
```

## ⚡ **Stage 3: 성능 테스트 (Performance Testing)**

### **대용량 처리 성능 테스트**
```bash
# 📊 1000개 페이지 동시 처리 테스트
claude --debug --print "Playwright로 1000개의 의료 뉴스 페이지를 동시에 크롤링할 때의 시스템 성능과 안정성 테스트"

# ✅ 성공 기준: 95% 이상 수집 성공률, 평균 응답시간 <5초, 메모리 사용량 <2GB
claude --print "Sequential로 처리 과정에서 병목 지점을 식별하고 최적화 제안 생성"

# 🔥 24시간 연속 운영 테스트
claude --debug --print "Context7에서 장기 운영 모니터링 방법을 찾고, 24시간 연속 크롤링 안정성 테스트"

# ✅ 성공 기준: 메모리 누수 없음, 오류율 <1%, 자동 복구 성공률 >90%
```

### **네트워크 스트레스 테스트**
```bash
# 🌐 네트워크 장애 대응 테스트
claude --debug --print "네트워크 연결 불안정, 타임아웃, 서버 오류 상황에서의 자동 복구 능력 테스트"

# ✅ 성공 기준: 3회 재시도 후 대안 경로 사용, 데이터 손실 <5%
claude --print "Sequential로 다양한 오류 시나리오별 복구 전략이 효과적으로 작동하는지 검증"

# 🚫 IP 차단 방지 효과성 테스트
claude --debug --print "User-Agent 로테이션, 요청 간격 조절 등 차단 방지 기법의 실제 효과 테스트"
```

### **동시성 및 확장성 테스트**
```bash
# 🔄 동시 다중 작업 처리 테스트
claude --debug --print "실시간 모니터링 + 일일 배치 수집 + 데이터 분석이 동시에 실행될 때의 시스템 성능 테스트"

# ✅ 성공 기준: CPU 사용률 <80%, 모든 작업 정상 완료, 우선순위 큐 정상 작동
claude --print "Context7에서 시스템 확장성 모범 사례를 확인하고, 더 많은 사이트 추가 시 성능 영향 예측"
```

## 🔍 **테스트 시나리오별 체크리스트**

### **기능 테스트 체크리스트**
| 테스트 항목 | 확인 사항 | 성공 기준 | 상태 |
|------------|----------|----------|------|
| **로그인 필요 사이트** | 자동 로그인 및 세션 유지 | 인증 성공률 >95% | ⏳ |
| **JavaScript 렌더링** | SPA/AJAX 콘텐츠 완전 수집 | 동적 콘텐츠 수집률 >90% | ⏳ |
| **파일 다운로드** | PDF, 이미지 자동 다운로드 | 파일 다운로드 성공률 >98% | ⏳ |
| **한글 인코딩** | 한글 텍스트 완벽 처리 | 인코딩 오류 <1% | ⏳ |
| **페이지네이션** | 모든 페이지 자동 탐색 | 전체 페이지 수집률 100% | ⏳ |

### **성능 테스트 체크리스트**
| 테스트 항목 | 측정 지표 | 목표 값 | 상태 |
|------------|----------|--------|------|
| **응답 시간** | 페이지당 평균 로딩 시간 | <3초 | ⏳ |
| **메모리 사용량** | 최대 메모리 사용량 | <1GB | ⏳ |
| **CPU 사용률** | 크롤링 중 평균 CPU 사용률 | <50% | ⏳ |
| **동시 연결 수** | 최대 동시 처리 가능 사이트 수 | >10개 | ⏳ |
| **데이터 처리량** | 시간당 처리 가능한 페이지 수 | >1000개 | ⏳ |

## 🧪 **실제 테스트 실행 스크립트**

### **단위 테스트 실행**
```bash
# 🔬 기본 크롤링 기능 테스트
claude --debug --print "Playwright로 대한의사협회 메인 페이지 접속 테스트: 연결 성공, HTML 파싱, 데이터 추출 검증"

# 결과 검증
claude --print "Sequential로 추출된 데이터의 완정성을 검사하고 품질 점수 산출"
```

### **통합 테스트 실행**  
```bash
# 🔗 전체 파이프라인 테스트
claude --debug --print "Context7에서 테스트 모범 사례를 확인하고, 수집부터 시각화까지 전체 프로세스 end-to-end 테스트"

# 성능 모니터링
claude --print "Desktop을 통해 테스트 중 시스템 리소스 사용량을 실시간 모니터링"
```

### **자동화된 테스트 스위트**
```bash
# 🤖 일일 자동 테스트 실행
claude --debug --print "매일 오전 5시에 자동으로 핵심 기능들을 테스트하고 결과를 Notion에 리포트하는 시스템 구축"

# 회귀 테스트
claude --print "Sequential로 새로운 기능 추가 시 기존 기능에 영향이 없는지 자동으로 회귀 테스트 실행"
```

## 📊 **테스트 결과 분석 및 리포팅**

### **자동 테스트 리포트 생성**
```bash
# 📈 테스트 결과 종합 분석
claude --debug --print "Sequential로 모든 테스트 결과를 분석하고, 성공률, 성능 지표, 개선 필요 영역을 식별"

# 📋 Notion 대시보드 업데이트
claude --print "테스트 결과를 Notion 대시보드에 자동으로 업데이트하고, 문제가 발견되면 알림 발송"

# 🔄 지속적 개선 제안
claude --debug --print "Context7에서 크롤링 개선 방법을 찾고, 테스트 결과를 바탕으로 구체적인 개선 계획 수립"
```

이제 크롤링 에이전트의 신뢰성과 성능을 완전히 검증할 수 있는 포괄적인 테스트 시스템이 구축되었습니다! 🧪✅